{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes:\n",
    "Given that the data appeared to be linear combinations, I thoughht a MLP would work well. Early testing was promizing, but actually still did not outperform thhe linear regression, so I created a workflow to track my iterative progress\n",
    "\n",
    "\n",
    "Determined the 4 best parforming architectures in testing on a subsample of train data:\n",
    "1. 3 layer pyramid w/ 44 hidden units\n",
    "2. 3 layer pyramid w/ 66 hidden units\n",
    "3. 2 layer pyramid w/ 44 hidden units\n",
    "4. 2 layer pyramid w/ 66 hidden units\n",
    "\n",
    "Fix ID column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "import os\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "# Pull the data from csv\n",
    "train_full = pd.read_csv(os.getcwd() + '/data/train_transformed_full.csv', index_col=False)\n",
    "test_full = pd.read_csv(os.getcwd() + '/data/test_transformed_full.csv', index_col=False)\n",
    "\n",
    "val_size = 2000\n",
    "\n",
    "#train_full = train_full.sample(frac=0.1, random_state=42)  # 10% random sample\n",
    "\n",
    "X_train_full = train_full.drop(columns=['target'])\n",
    "y_train_full = train_full['target']\n",
    "\n",
    "X_train = X_train_full.iloc[:-val_size]\n",
    "y_train = y_train_full.iloc[:-val_size]\n",
    "\n",
    "X_val = X_train_full.iloc[-val_size:]\n",
    "y_val = y_train_full.iloc[-val_size:]\n",
    "\n",
    "X_test = test_full.drop(columns=['target'])\n",
    "y_test = test_full['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 25\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train.values, dtype=torch.float32)\n",
    "X_val_tensor = torch.tensor(X_val.values, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test.values, dtype=torch.float32)\n",
    "\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).view(y_train.shape[0], 1)\n",
    "y_val_tensor = torch.tensor(y_val.values, dtype=torch.float32).view(y_val.shape[0], 1)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32).view(y_test.shape[0], 1)\n",
    "\n",
    "# Create Dataset and DataLoader\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    \n",
    "#------------------------ 1 Layer Architectures ------------------------\n",
    "\n",
    "class SingleLayerMLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(SingleLayerMLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.output = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu1(out)\n",
    "        out= self.output(out)\n",
    "        return out\n",
    "    \n",
    "#------------------------ 2 Layer Architectures ------------------------\n",
    "\n",
    "# Stacked\n",
    "class StackedDoubleLayerMLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(StackedDoubleLayerMLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.output = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu1(out)\n",
    "        out= self.fc2(out)\n",
    "        out= self.relu2(out)\n",
    "        out = self.output(out)\n",
    "        return out\n",
    "\n",
    "# Pyramid \n",
    "class PyramidDoubleLayerMLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(PyramidDoubleLayerMLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, int(hidden_size/2))\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.output = nn.Linear(int(hidden_size/2), output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu1(out)\n",
    "        out= self.fc2(out)\n",
    "        out= self.relu2(out)\n",
    "        out = self.output(out)\n",
    "        return out\n",
    "    \n",
    "#------------------------ 3 Layer Architectures ------------------------\n",
    "      \n",
    "# Stacked  \n",
    "class StackedTripleLayerMLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(StackedTripleLayerMLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.output = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu1(out)\n",
    "        out= self.fc2(out)\n",
    "        out= self.relu2(out)\n",
    "        out = self.fc3(out)\n",
    "        out = self.relu3(out)\n",
    "        out=self.output(out)\n",
    "        return out\n",
    "    \n",
    "# Pyramid   \n",
    "class PyramidTripleLayerMLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(PyramidTripleLayerMLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, int(hidden_size/2))\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(int(hidden_size/2), int(hidden_size/4))\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.output = nn.Linear(int(hidden_size/4), output_size)\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu1(out)\n",
    "        out= self.fc2(out)\n",
    "        out= self.relu2(out)\n",
    "        out = self.fc3(out)\n",
    "        out = self.relu3(out)\n",
    "        out=self.output(out)\n",
    "        return out\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.00133, Val Loss: 0.00039 \n",
      "Epoch [2/10], Loss: 0.00038, Val Loss: 0.00038 \n",
      "Epoch [3/10], Loss: 0.00037, Val Loss: 0.00038 \n",
      "Epoch [4/10], Loss: 0.00037, Val Loss: 0.00038 \n",
      "Epoch [5/10], Loss: 0.00037, Val Loss: 0.00038 \n",
      "Epoch [6/10], Loss: 0.00037, Val Loss: 0.00038 \n",
      "Epoch [7/10], Loss: 0.00036, Val Loss: 0.00037 \n",
      "Epoch [8/10], Loss: 0.00036, Val Loss: 0.00038 \n",
      "Epoch [9/10], Loss: 0.00036, Val Loss: 0.00038 \n",
      "Epoch [10/10], Loss: 0.00036, Val Loss: 0.00038 \n",
      "Training complete\n"
     ]
    }
   ],
   "source": [
    "# Model parameters\n",
    "input_size = X_train_tensor.shape[1]\n",
    "hidden_size = 44 \n",
    "output_size = 1  # Single continuous value for regression\n",
    "\n",
    "# Create the model - stacked double seems best so far\n",
    "selected_architecture = PyramidTripleLayerMLP\n",
    "\n",
    "model = selected_architecture(input_size, hidden_size, output_size)\n",
    "\n",
    "writer = SummaryWriter(f\"runs/{selected_architecture}/{hidden_size}/{timestamp}\")\n",
    "\n",
    "# Define loss and optimizer\n",
    "criterion = nn.MSELoss()  \n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "sample_input, sample_targets = next(iter(train_loader))\n",
    "writer.add_graph(model, sample_input)\n",
    "\n",
    "device =torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "\n",
    "best_val_r2 = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    # Train\n",
    "    model.train(True)\n",
    "    running_train_loss = 0\n",
    "    running_train_r2 = 0\n",
    "    \n",
    "    for inputs, targets in train_loader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        train_loss = criterion(outputs, targets)\n",
    "        # Backward pass\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "        running_train_loss += train_loss.item()\n",
    "        # Calculate R2\n",
    "        outputs_np = outputs.detach().cpu().numpy()\n",
    "        targets_np = targets.detach().cpu().numpy()\n",
    "        train_batch_r2 = r2_score(targets_np, outputs_np)\n",
    "        running_train_r2 += train_batch_r2\n",
    "        \n",
    "    # Validate \n",
    "    model.train(False) # Turn off tracking to validate\n",
    "    running_val_loss = 0\n",
    "    running_val_r2 = 0\n",
    "\n",
    "    for inputs, targets in val_loader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        # Make prediction\n",
    "        outputs = model(inputs)\n",
    "        # Compute loss\n",
    "        val_loss = criterion(outputs, targets)\n",
    "        running_val_loss += val_loss.item()\n",
    "        #Calculate R2\n",
    "        outputs_np = outputs.detach().cpu().numpy()\n",
    "        targets_np = targets.detach().cpu().numpy()\n",
    "        val_batch_r2 = r2_score(targets_np, outputs_np)\n",
    "        running_val_r2 += val_batch_r2\n",
    "     \n",
    "    # Compute the averages for each metric across all batches in the epochh   \n",
    "    train_loss_epoch = running_train_loss / len(train_loader)\n",
    "    val_loss_epoch = running_val_loss / len(val_loader)\n",
    "    train_r2_epoch = running_train_r2 / len(train_loader)\n",
    "    val_r2_epoch =  running_val_r2 / len(val_loader)\n",
    "    \n",
    "    metrics_dict = {\n",
    "        'train loss': train_loss_epoch,\n",
    "        'validation loss': val_loss_epoch,\n",
    "        'train R2': train_r2_epoch,\n",
    "        'validation R2': val_r2_epoch\n",
    "    }\n",
    "    \n",
    "    # Best Model Logging\n",
    "    if val_r2_epoch > best_val_r2:\n",
    "        best_val_r2 = val_r2_epoch\n",
    "        best_model_state = model.state_dict()\n",
    "        best_model_metrics = metrics_dict\n",
    "        \n",
    "    #writer.add_scalar('Loss/Train Loss', train_loss.item(), epoch + 1)\n",
    "    #writer.add_scalar('Loss/Validation Loss', val_loss.item(), epoch + 1)\n",
    "\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {train_loss_epoch:.5f}, Val Loss: {val_loss_epoch:.5f} ')\n",
    "    \n",
    "best_model_path = 'models/model_{}_{}'.format(timestamp, (epoch + 1))\n",
    "torch.save(best_model_state, best_model_path)\n",
    "#writer.add_scalars(main_tag='best model metrics', tag_scalar_dict = best_model_metrics)\n",
    "\n",
    "print(\"Training complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training r2: 0.8444, test r2: 0.8450\n"
     ]
    }
   ],
   "source": [
    "# Inference function\n",
    "def inference(model, input_data):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        predictions = model(input_data)\n",
    "    return predictions\n",
    "\n",
    "# Example inference on the test set\n",
    "best_model= selected_architecture(input_size, hidden_size, output_size).load_state_dict(torch.load(best_model_path))\n",
    "\n",
    "predictions = inference(model, X_test_tensor)\n",
    "\n",
    "test_score = r2_score(predictions, y_test_tensor)\n",
    "train_score = r2_score(inference(model, X_train_tensor), y_train_tensor)\n",
    "print(f'training r2: {train_score:.4f}, test r2: {test_score:.4f}')\n",
    "\n",
    "writer.add_scalar('test_r2', test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Convert tensors to numpy arrays\n",
    "actual_np = y_test_tensor.numpy()\n",
    "predicted_np = predictions.numpy()\n",
    "\n",
    "# Calculate residuals\n",
    "residuals = actual_np - predicted_np\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Plot residuals\n",
    "ax.scatter(predicted_np, residuals, color='blue', edgecolors='k', alpha=0.7)\n",
    "ax.hlines(0, min(predicted_np) - 1, max(predicted_np) + 1, colors='r', linestyles='dashed')\n",
    "ax.set_title('Residual Plot')\n",
    "ax.set_xlabel('Predicted Values')\n",
    "ax.set_ylabel('Residuals')\n",
    "\n",
    "residual_plot_figure = fig\n",
    "\n",
    "writer.add_figure('residuals', figure=residual_plot_figure)\n",
    "\n",
    "writer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [],
   "source": [
    "# started w/ hidden size = 50, 10 epochs, batch size = 25\n",
    "submission_dataset = pd.read_csv('./data/submission_features.csv')\n",
    "\n",
    "submission_ids = submission_dataset['id']\n",
    "submission_features = submission_dataset.drop(columns=['id'])\n",
    "submission_feature_tensor = torch.tensor(submission_features.values, dtype=torch.float32)\n",
    "\n",
    "submission_preds = inference(model, submission_feature_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame(data= {\n",
    "    'id' : submission_ids,\n",
    "    'FloodProbability' : submission_preds.view(submission_preds.shape[0]).numpy()\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>FloodProbability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1117957</td>\n",
       "      <td>0.575060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1117958</td>\n",
       "      <td>0.452776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1117959</td>\n",
       "      <td>0.451303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1117960</td>\n",
       "      <td>0.468913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1117961</td>\n",
       "      <td>0.471428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745300</th>\n",
       "      <td>1863257</td>\n",
       "      <td>0.475419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745301</th>\n",
       "      <td>1863258</td>\n",
       "      <td>0.438622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745302</th>\n",
       "      <td>1863259</td>\n",
       "      <td>0.623228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745303</th>\n",
       "      <td>1863260</td>\n",
       "      <td>0.552715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745304</th>\n",
       "      <td>1863261</td>\n",
       "      <td>0.528328</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>745305 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id  FloodProbability\n",
       "0       1117957          0.575060\n",
       "1       1117958          0.452776\n",
       "2       1117959          0.451303\n",
       "3       1117960          0.468913\n",
       "4       1117961          0.471428\n",
       "...         ...               ...\n",
       "745300  1863257          0.475419\n",
       "745301  1863258          0.438622\n",
       "745302  1863259          0.623228\n",
       "745303  1863260          0.552715\n",
       "745304  1863261          0.528328\n",
       "\n",
       "[745305 rows x 2 columns]"
      ]
     },
     "execution_count": 518,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv('./result.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "baseball",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
